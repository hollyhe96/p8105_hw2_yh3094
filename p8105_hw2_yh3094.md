p8105\_hw2\_yh3094
================
Yun He
September 27, 2018

Problem 1
=========

Import and clean NYC transit dataset
------------------------------------

``` r
transit_data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE)) 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
transit_data
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu~ route1 route2
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr> 
    ##  1 4 Av~ 25th St                  40.7            -74.0 R      <NA>  
    ##  2 4 Av~ 25th St                  40.7            -74.0 R      <NA>  
    ##  3 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  4 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  5 4 Av~ 36th St                  40.7            -74.0 N      R     
    ##  6 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  7 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  8 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ##  9 4 Av~ 45th St                  40.6            -74.0 R      <NA>  
    ## 10 4 Av~ 53rd St                  40.6            -74.0 R      <NA>  
    ## # ... with 1,858 more rows, and 13 more variables: route3 <chr>,
    ## #   route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>, route8 <int>,
    ## #   route9 <int>, route10 <int>, route11 <int>, entrance_type <chr>,
    ## #   entry <lgl>, vending <chr>, ada <lgl>

The dataset contains variables of line, station name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. I first imported the dataset using `read_csv`, cleaned all variable names using `janitor::clean_names`, and then preserved the variables that I wanted using `select`, and finally, I converted the entry variable from character (YES vs NO) to a logical variable (TRUE vs FALSE) using `recode`. After all cleaning steps above, the final dataset contains 1868 rows and 19 columns. In my opinion, these data are untidy because the route variable was spreaded into 11 variables.

Calculate the sum of distinct stations
--------------------------------------

``` r
nrow(distinct(transit_data, line, station_name))
```

    ## [1] 465

There are 465 distinct stations.

Calculate the sum of ADA compliant stations
-------------------------------------------

``` r
sum(distinct(transit_data, line, station_name, ada)$ada)
```

    ## [1] 84

There are 84 ADA compliant stations.

Calculate the proportion of stations without vending allow entrance
-------------------------------------------------------------------

``` r
nrow(filter(transit_data, vending == 'NO'))/nrow(transit_data)
```

    ## [1] 0.09796574

The proportion of station entrances / exits without vending allow entrance is 0.098.

Reformat data so that route number and route name are distinct variables
------------------------------------------------------------------------

``` r
transit_data_reformat = 
  transit_data %>% 
  gather(key = route_number, value = route_name, route1:route11)
transit_data_reformat
```

    ## # A tibble: 20,548 x 10
    ##    line  station_name station_latitude station_longitu~ entrance_type entry
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>         <lgl>
    ##  1 4 Av~ 25th St                  40.7            -74.0 Stair         TRUE 
    ##  2 4 Av~ 25th St                  40.7            -74.0 Stair         TRUE 
    ##  3 4 Av~ 36th St                  40.7            -74.0 Stair         TRUE 
    ##  4 4 Av~ 36th St                  40.7            -74.0 Stair         TRUE 
    ##  5 4 Av~ 36th St                  40.7            -74.0 Stair         TRUE 
    ##  6 4 Av~ 45th St                  40.6            -74.0 Stair         TRUE 
    ##  7 4 Av~ 45th St                  40.6            -74.0 Stair         TRUE 
    ##  8 4 Av~ 45th St                  40.6            -74.0 Stair         TRUE 
    ##  9 4 Av~ 45th St                  40.6            -74.0 Stair         TRUE 
    ## 10 4 Av~ 53rd St                  40.6            -74.0 Stair         TRUE 
    ## # ... with 20,538 more rows, and 4 more variables: vending <chr>,
    ## #   ada <lgl>, route_number <chr>, route_name <chr>

Calculate distinct stations that serve the A train
--------------------------------------------------

``` r
transit_data_A = 
  transit_data_reformat %>% 
  filter(route_name == 'A')
nrow(distinct(transit_data_A, line, station_name))
```

    ## [1] 60

There are 60 distinct stations that serve the A train.

Calculate ADA compliant stations that serve the A train
-------------------------------------------------------

``` r
filter(transit_data_A, ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 17

Of the stations that serve the A train, 17 are ADA compliant.

Problem 2
=========

Import and clean the Mr. Trash Wheel sheet
------------------------------------------

``` r
wheel_data = 
  read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
             sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = round(sports_balls)) %>% 
  mutate(sports_balls = as.integer(sports_balls))
wheel_data
```

    ## # A tibble: 216 x 14
    ##    dumpster month  year date                weight_tons volume_cubic_ya~
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31               18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74               13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45               15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06               18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71               13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52               14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76               18
    ## # ... with 206 more rows, and 8 more variables: plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>

Read and clean precipitation data for 2016 and 2017
---------------------------------------------------

``` r
precipiation_data_2016 = 
  read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
             sheet = "2016 Precipitation", range = cell_rows(2:14)) %>%
  janitor::clean_names() %>%
  filter(!is.na(total)) %>% 
  mutate(year = 2016) 

precipitation_data_2017 = 
  read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
             sheet = "2017 Precipitation", range = cell_rows(2:14)) %>%
  janitor::clean_names() %>%
  filter(!is.na(total)) %>% 
  mutate(year = 2017)

precipitation_data = 
  full_join(precipiation_data_2016, precipitation_data_2017) %>% 
  mutate(month = month.name[month])
```

    ## Joining, by = c("month", "total", "year")

``` r
precipitation_data
```

    ## # A tibble: 20 x 3
    ##    month     total  year
    ##    <chr>     <dbl> <dbl>
    ##  1 January    3.23  2016
    ##  2 February   5.32  2016
    ##  3 March      2.24  2016
    ##  4 April      1.78  2016
    ##  5 May        5.19  2016
    ##  6 June       3.2   2016
    ##  7 July       6.09  2016
    ##  8 August     3.96  2016
    ##  9 September  4.53  2016
    ## 10 October    0.62  2016
    ## 11 November   1.47  2016
    ## 12 December   2.32  2016
    ## 13 January    2.34  2017
    ## 14 February   1.46  2017
    ## 15 March      3.57  2017
    ## 16 April      3.99  2017
    ## 17 May        5.64  2017
    ## 18 June       1.4   2017
    ## 19 July       7.09  2017
    ## 20 August     4.44  2017

Problem 3
=========
